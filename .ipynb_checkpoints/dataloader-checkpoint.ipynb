{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mport os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import collections\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniImagenet(Dataset):\n",
    "    \"\"\"\n",
    "    put mini-imagenet files as :\n",
    "    root :\n",
    "        |- images/*.jpg includes all imgeas\n",
    "        |- train.csv\n",
    "        |- test.csv\n",
    "        |- val.csv\n",
    "    NOTICE: meta-learning is different from general supervised learning, especially the concept of batch and set.\n",
    "    batch: contains several sets\n",
    "    sets: conains n_way * k_shot for meta-train set, n_way * n_query for meta-test set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "        \"\"\"\n",
    "\n",
    "        :param root: root path of mini-imagenet\n",
    "        :param mode: train, val or test\n",
    "        :param batchsz: batch size of sets, not batch of imgs 任务的个数\n",
    "        :param n_way:\n",
    "        :param k_shot:\n",
    "        :param k_query: num of qeruy imgs per class\n",
    "        :param resize: resize to\n",
    "        :param startidx: start to index label from startidx  从第startidx类开始的\n",
    "        \"\"\"\n",
    "\n",
    "        self.batchsz = batchsz  # batch of set, not batch of imgs\n",
    "        self.n_way = n_way  # n-way\n",
    "        self.k_shot = k_shot  # k-shot\n",
    "        self.k_query = k_query  # for evaluation\n",
    "        self.setsz = self.n_way * self.k_shot  # num of samples per set\n",
    "        self.querysz = self.n_way * self.k_query  # number of samples per set for evaluation\n",
    "        self.resize = resize  # resize to\n",
    "        self.startidx = startidx  # index label not from 0, but from startidx\n",
    "        print('shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d' % (\n",
    "        mode, batchsz, n_way, k_shot, k_query, resize))\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.transform = transforms.Compose([lambda x: Image.open(x).convert('RGB'),\n",
    "                                                 transforms.Resize((self.resize, self.resize)),\n",
    "                                                 # transforms.RandomHorizontalFlip(),\n",
    "                                                 # transforms.RandomRotation(5),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # 用均值和标准差归一化一张图像\n",
    "                                                 ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([lambda x: Image.open(x).convert('RGB'),\n",
    "                                                 transforms.Resize((self.resize, self.resize)),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                                 ])\n",
    "\n",
    "        self.path = os.path.join(root, 'images')  # image path\n",
    "        csvdata = self.loadCSV(os.path.join(root, mode + '.csv'))  # csv path\n",
    "        self.data = []\n",
    "        self.img2label = {}\n",
    "        for i, (k, v) in enumerate(csvdata.items()):   # k-img_name i-class v-img\n",
    "            self.data.append(v)  # [[img1, img2, ...], [img111, ...]]\n",
    "            self.img2label[k] = i + self.startidx  # {\"img_name[:9]\":label}\n",
    "        self.cls_num = len(self.data)\n",
    "\n",
    "        self.create_batch(self.batchsz)\n",
    "\n",
    "    def loadCSV(self, csvf):\n",
    "        \"\"\"\n",
    "        return a dict saving the information of csv\n",
    "        :param splitFile: csv file name\n",
    "        :return: {label:[file1, file2 ...]} 将图片按类进行划分，放在字典里\n",
    "        \"\"\"\n",
    "        dictLabels = {}\n",
    "        with open(csvf) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=',')\n",
    "            next(csvreader, None)  # skip (filename, label)\n",
    "            for i, row in enumerate(csvreader):\n",
    "                filename = row[0]\n",
    "                label = row[1]\n",
    "                # append filename to current label\n",
    "                if label in dictLabels.keys():\n",
    "                    dictLabels[label].append(filename)\n",
    "                else:\n",
    "                    dictLabels[label] = [filename]\n",
    "        return dictLabels\n",
    "\n",
    "    def create_batch(self, batchsz):\n",
    "        \"\"\"\n",
    "        create batch for meta-learning.\n",
    "        ×episode× here means batch, and it means how many sets we want to retain.\n",
    "        :param episodes: batch size\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.support_x_batch = []  # support set batch\n",
    "        self.query_x_batch = []  # query set batch\n",
    "        for b in range(batchsz):  # for each batch\n",
    "            # 1.select n_way classes randomly\n",
    "            selected_cls = np.random.choice(self.cls_num, self.n_way, False)  # no duplicate\n",
    "            np.random.shuffle(selected_cls)\n",
    "            support_x = []\n",
    "            query_x = []\n",
    "            for cls in selected_cls:\n",
    "                # 2. select k_shot + k_query for each class\n",
    "                selected_imgs_idx = np.random.choice(len(self.data[cls]), self.k_shot + self.k_query, False)\n",
    "                np.random.shuffle(selected_imgs_idx)\n",
    "                indexDtrain = np.array(selected_imgs_idx[:self.k_shot])  # idx for Dtrain\n",
    "                indexDtest = np.array(selected_imgs_idx[self.k_shot:])  # idx for Dtest\n",
    "                support_x.append(\n",
    "                    np.array(self.data[cls])[indexDtrain].tolist())  # get all images filename for current Dtrain\n",
    "                query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "            # shuffle the correponding relation between support set and query set\n",
    "            random.shuffle(support_x)\n",
    "            random.shuffle(query_x)\n",
    "\n",
    "            self.support_x_batch.append(support_x)  # append set to current sets\n",
    "            self.query_x_batch.append(query_x)  # append sets to current sets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        index means index of sets, 0<= index <= batchsz-1\n",
    "        :param index:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # [setsz, 3, resize, resize]\n",
    "        support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "        # [setsz]\n",
    "        support_y = np.zeros((self.setsz), dtype=np.int)\n",
    "        # [querysz, 3, resize, resize]\n",
    "        query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "        # [querysz]\n",
    "        query_y = np.zeros((self.querysz), dtype=np.int)\n",
    "\n",
    "        flatten_support_x = [os.path.join(self.path, item)\n",
    "                             for sublist in self.support_x_batch[index] for item in sublist]\n",
    "        support_y = np.array(\n",
    "            [self.img2label[item[:9]]  # filename:n0153282900000005.jpg, the first 9 characters treated as label\n",
    "             for sublist in self.support_x_batch[index] for item in sublist]).astype(np.int32)\n",
    "\n",
    "        flatten_query_x = [os.path.join(self.path, item)\n",
    "                           for sublist in self.query_x_batch[index] for item in sublist]\n",
    "        query_y = np.array([self.img2label[item[:9]]\n",
    "                            for sublist in self.query_x_batch[index] for item in sublist]).astype(np.int32)\n",
    "\n",
    "        # print('global:', support_y, query_y)\n",
    "        # support_y: [setsz]\n",
    "        # query_y: [querysz]\n",
    "        # unique: [n-way], sorted\n",
    "        unique = np.unique(support_y)\n",
    "        random.shuffle(unique)\n",
    "        # relative means the label ranges from 0 to n-way\n",
    "        support_y_relative = np.zeros(self.setsz)\n",
    "        query_y_relative = np.zeros(self.querysz)\n",
    "        for idx, l in enumerate(unique):\n",
    "            support_y_relative[support_y == l] = idx\n",
    "            query_y_relative[query_y == l] = idx\n",
    "\n",
    "        # print('relative:', support_y_relative, query_y_relative)\n",
    "\n",
    "        for i, path in enumerate(flatten_support_x):\n",
    "            support_x[i] = self.transform(path)\n",
    "\n",
    "        for i, path in enumerate(flatten_query_x):\n",
    "            query_x[i] = self.transform(path)\n",
    "        # print(support_set_y)\n",
    "        # return support_x, torch.LongTensor(support_y), query_x, torch.LongTensor(query_y)\n",
    "\n",
    "        return support_x, torch.LongTensor(support_y_relative), query_x, torch.LongTensor(query_y_relative)\n",
    "\n",
    "    def __len__(self):\n",
    "        # as we have built up to batchsz of sets, you can sample some small batch size of sets.\n",
    "        return self.batchsz\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # the following episode is to view one set of images via tensorboard.\n",
    "    from torchvision.utils import make_grid\n",
    "    from matplotlib import pyplot as plt\n",
    "    from tensorboardX import SummaryWriter\n",
    "    import time\n",
    "\n",
    "    plt.ion()\n",
    "\n",
    "    tb = SummaryWriter('runs', 'mini-imagenet')\n",
    "    mini = MiniImagenet('../mini-imagenet/', mode='train', n_way=5, k_shot=1, k_query=1, batchsz=1000, resize=168)\n",
    "\n",
    "    for i, set_ in enumerate(mini):   # i-batch的索引 set-batch的数据\n",
    "        # support_x: [k_shot*n_way, 3, 84, 84]\n",
    "        support_x, support_y, query_x, query_y = set_\n",
    "\n",
    "        support_x = make_grid(support_x, nrow=2) # 将图像拼接成一张大图\n",
    "        query_x = make_grid(query_x, nrow=2)\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.imshow(support_x.transpose(2, 0).numpy())\n",
    "        plt.pause(0.5)\n",
    "        plt.figure(2)\n",
    "        plt.imshow(query_x.transpose(2, 0).numpy())\n",
    "        plt.pause(0.5)\n",
    "\n",
    "        tb.add_image('support_x', support_x)\n",
    "        tb.add_image('query_x', query_x)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    tb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
