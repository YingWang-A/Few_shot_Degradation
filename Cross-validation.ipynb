{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ddde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "from scipy.linalg import block_diag\n",
    "from numpy.linalg import inv\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy.matlib as nm\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]  =  \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4734078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_params(num_inputs, num_hiddens, num_outputs, num_units):\n",
    "    \n",
    "    def normal(shape):\n",
    "        return Variable(nn.Parameter(torch.randn(size = shape))) * 0.01\n",
    "    def zero(shape):\n",
    "        return Variable(nn.Parameter(torch.zeros(shape)))\n",
    "    def three(num_inputs, num_hiddens, num_outputs):\n",
    "        return (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), zero(num_hiddens))\n",
    "    \n",
    "    W_xi, W_hi, b_i = three(num_inputs, num_hiddens, num_outputs) # 输入门参数\n",
    "    W_xf, W_hf, b_f = three(num_inputs, num_hiddens, num_outputs) # 遗忘门参数\n",
    "    W_xo, W_ho, b_o = three(num_inputs, num_hiddens, num_outputs) # 输出门参数\n",
    "    W_xc, W_hc, b_c = three(num_inputs, num_hiddens, num_outputs) # 候选记忆门参数\n",
    "    \n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_units, num_hiddens, num_outputs))\n",
    "    \n",
    "    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    \n",
    "    return params \n",
    "\n",
    "def init_lstm_state(batch_size, num_hiddens):\n",
    "    return (torch.ones(batch_size, num_hiddens)*(-20.0), \n",
    "            torch.ones(batch_size, num_hiddens)*(-20.0))\n",
    "\n",
    "def init_lstm_state(batch_size, num_hiddens):\n",
    "    return (torch.ones(batch_size, num_hiddens)*(-20.0), \n",
    "            torch.ones(batch_size, num_hiddens)*(-20.0))\n",
    "\n",
    "def lstm(inputs, state, unit_index, params):\n",
    "    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c] = params[:12]\n",
    "    W_hq = params[12][unit_index]\n",
    "    (H, C) = state\n",
    "    \n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)\n",
    "        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)\n",
    "        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)\n",
    "\n",
    "        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)\n",
    "        C = F * C + I * C_tilda \n",
    "        H = O * torch.relu(C)\n",
    "        Y = H @ W_hq\n",
    "        outputs.append(Y)\n",
    "\n",
    "    return torch.cat(outputs, dim = 0)\n",
    "\n",
    "class RNNModelScratch():\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, \n",
    "                 num_units, get_params, init_state, forward_fn):   \n",
    "        self.num_inputs, self.num_hiddens = num_inputs, num_hiddens\n",
    "        self.num_outputs, self.num_units = num_outputs, num_units\n",
    "        self.params = get_params(num_inputs, num_hiddens, num_outputs, num_units)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "        \n",
    "    def __call__(self, X, state, unit_index):\n",
    "        return self.forward_fn(X, state, unit_index, self.params)\n",
    "    \n",
    "    def begin_state(self, batch_size):\n",
    "        return self.init_state(batch_size, self.num_hiddens)\n",
    "    \n",
    "class SVGD():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def svgd_kernel(self, theta, h = -1):\n",
    "        sq_dist = pdist(theta)\n",
    "        pairwise_dists = squareform(sq_dist)**2  # 转化为距离矩阵\n",
    "        if h < 0: # if h < 0, using median trick\n",
    "            h = np.median(pairwise_dists)  \n",
    "            h = np.sqrt(0.5 * h / np.log(theta.shape[0]+1))\n",
    "\n",
    "        # compute the rbf kernel\n",
    "        Kxy = np.exp( -pairwise_dists / h**2 / 2)\n",
    "\n",
    "        dxkxy = -np.matmul(Kxy, theta)\n",
    "        sumkxy = np.sum(Kxy, axis=1)\n",
    "        for i in range(theta.shape[1]):\n",
    "            dxkxy[:, i] = dxkxy[:,i] + np.multiply(theta[:,i],sumkxy)\n",
    "        dxkxy = dxkxy / (h**2)\n",
    "        return (Kxy, dxkxy)\n",
    "    \n",
    " \n",
    "    def update(self, x0, historical_grad, lnprob, n_iter, stepsize, bandwidth = -1, alpha = 0.9, debug = False):\n",
    "        # Check input\n",
    "        if x0 is None or lnprob is None:\n",
    "            raise ValueError('x0 or lnprob cannot be None!')\n",
    "        \n",
    "        theta = np.copy(x0) \n",
    "        \n",
    "        # adagrad with momentum\n",
    "        fudge_factor = 1e-6\n",
    "        # historical_grad = 0\n",
    "        # for iter in range(n_iter):\n",
    "        #    if debug and (iter+1) % 1000 == 0:\n",
    "        #        print('iter ' + str(iter+1))\n",
    "            \n",
    "        lnpgrad = lnprob(theta)\n",
    "        # calculating the kernel matrix\n",
    "        kxy, dxkxy = self.svgd_kernel(theta, h = -1)  \n",
    "        grad_theta = (np.matmul(kxy, lnpgrad) + dxkxy) / x0.shape[0]  \n",
    "\n",
    "        # adagrad \n",
    "        if n_iter == 0:\n",
    "            historical_grad = historical_grad + grad_theta ** 2\n",
    "        historical_grad = alpha * historical_grad + (1 - alpha) * (grad_theta ** 2)\n",
    "        \n",
    "        adj_grad = np.divide(grad_theta, fudge_factor+np.sqrt(historical_grad))\n",
    "        # theta = theta + stepsize * adj_grad \n",
    "            \n",
    "        return adj_grad, historical_grad\n",
    "    \n",
    "class MVN:\n",
    "    def __init__(self, mu, A):\n",
    "        self.mu = mu\n",
    "        self.A = A # 协方差的逆矩阵\n",
    "    \n",
    "    def dlnprob(self, theta):\n",
    "        return -1*np.matmul(theta-nm.repmat(self.mu, theta.shape[0], 1), self.A)\n",
    "    \n",
    "def train(net, lr, num_epochs, inputs, targets, batch_size, model, step_size, valid_obv):\n",
    "    # train(net, lr, num_epochs, X, train_data, batch_size, model, step_size, valid_obv)\n",
    "    loss = nn.MSELoss()\n",
    "    updater = optim.Adam(net.params, lr)\n",
    "    num_unit = len(inputs)\n",
    "    \n",
    "    historical_grad = 0\n",
    "    loss_lt = np.zeros(num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        L = torch.zeros(num_unit)      \n",
    "        for i in range(num_unit):\n",
    "            tmp_obv = valid_obv[i]\n",
    "            state = net.begin_state(batch_size)\n",
    "            y_preb = net(inputs[i], state, i)\n",
    "            L[i] = loss(y_preb[tmp_obv], targets[i][tmp_obv])\n",
    "        \n",
    "        tmp_gamma = net.params[12].detach().permute(0,2,1).numpy().reshape(num_unit, -1)\n",
    "        grad, historical_grad = SVGD().update(tmp_gamma, historical_grad, model.dlnprob, epoch, step_size)\n",
    "        \n",
    "        loss_lt[epoch] = L.mean().item()\n",
    "        updater.zero_grad()\n",
    "        L.mean().backward()\n",
    "        updater.step()\n",
    "        \n",
    "        net.params[12].data += step_size * torch.tensor(grad.reshape(num_unit,3,num_sensors), dtype=torch.float)\n",
    "        # net.params[12] = torch.tensor(net.params[12].detach().numpy(), dtype=torch.float, requires_grad=True)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print('epoch:{}/{}'.format(epoch+1, num_epochs))\n",
    "            print('Loss:', L.mean().item())\n",
    "\n",
    "    print('finished training!')\n",
    "\n",
    "    return loss_lt\n",
    "\n",
    "def get_H(inputs, params, num_hiddens):\n",
    "    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c] = params[:12]\n",
    "    (H, C) = init_lstm_state(1, num_hiddens)\n",
    "    H_lt = torch.zeros((len(inputs), num_hiddens))\n",
    "    for i in range(len(inputs)):\n",
    "        X = inputs[i]\n",
    "        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)\n",
    "        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)\n",
    "        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)\n",
    "\n",
    "        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)\n",
    "        C = F * C + I * C_tilda \n",
    "        H = O * torch.relu(C)\n",
    "        \n",
    "        H_lt[i] = H\n",
    "    \n",
    "    return H_lt\n",
    "\n",
    "def predict_sensors(net, inputs, targets, unit_index): \n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    state = net.begin_state(1)\n",
    "    y_preb = net(inputs, state, unit_index)\n",
    "    \n",
    "    for i in range(6):\n",
    "        plt.subplot(2, 3, 1+i)\n",
    "        plt.plot(targets[8:,i], 'o', alpha=0.5)\n",
    "        plt.plot(y_preb[8:,i].detach().numpy(), color='#FF8D57', linewidth = 3)\n",
    "        \n",
    "    plt.subplots_adjust(wspace = 0.25, hspace = 0.35)\n",
    "    plt.show()\n",
    "    \n",
    "def RMSE(true_RUL, pred_RUL):\n",
    "    d = true_RUL - pred_RUL\n",
    "    return np.sqrt(np.power(d,2).mean())\n",
    "\n",
    "def score(true_RUL, pred_RUL):\n",
    "    d = pred_RUL - true_RUL\n",
    "    n = len(true_RUL)\n",
    "    score = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        d_i = d[i]\n",
    "        if d_i >= 0:\n",
    "            score[i] = np.exp(d_i/10) - 1\n",
    "        elif d_i < 0:\n",
    "            score[i] = np.exp(-d_i/13) - 1\n",
    "    return score.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621b6634",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.load('cov1.npy')\n",
    "mu = np.load('mu1.npy').reshape(-1)\n",
    "\n",
    "model1 = MVN(mu, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d2fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  读入训练数据\n",
    "df_train = pd.read_csv('train_data.csv')\n",
    "num_units = df_train['Unit'].max()\n",
    "num_train = 20\n",
    "num_test = num_units - num_train\n",
    "num_sensors = 6\n",
    "\n",
    "np.random.seed(111)\n",
    "selected_unit = np.random.choice(num_units, num_units, replace=False)\n",
    "\n",
    "t = [torch.tensor([i/500.0]) for i in range(500)]\n",
    "T = []\n",
    "train_data = []\n",
    "lengths = []\n",
    "\n",
    "for i in selected_unit[:num_train]:\n",
    "    sensor_data = torch.tensor(df_train[df_train['Unit'] == i+1].iloc[:,2:].values, dtype = torch.float)  \n",
    "    T.append(t[:sensor_data.shape[0]])\n",
    "    train_data.append(sensor_data)\n",
    "    lengths.append(len(sensor_data)) \n",
    "    \n",
    "test_data = []\n",
    "test_lengths = []\n",
    "test_RUL = []\n",
    "\n",
    "for i in selected_unit[num_train:]:\n",
    "    sensor_data = np.array(df_train[df_train['Unit']==i+1].iloc[:,2:]) \n",
    "    tmp_n = np.random.randint(80,303)\n",
    "    while tmp_n > len(sensor_data):\n",
    "        tmp_n = np.random.randint(100,303)\n",
    "    test_data.append(sensor_data[:tmp_n])\n",
    "    test_lengths.append(tmp_n)\n",
    "    test_RUL.append(len(sensor_data)-tmp_n) \n",
    "\n",
    "test_RUL = np.array(test_RUL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62443776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51, 56, 85, 47, 18, 79, 62, 48, 80, 22])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_unit[num_train:num_train+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7eeba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141, 132, 235, 187,  85, 107, 146, 177, 128, 108]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_lengths).reshape(1,-1)[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d53f56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 1\n",
    "num_hiddens = 3\n",
    "num_outputs = 6\n",
    "net = RNNModelScratch(num_inputs, num_hiddens, num_outputs, num_train, get_lstm_params, init_lstm_state, lstm)\n",
    "net.params = torch.load('LSTM-SVGD(20)-1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e45cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = get_H(t, net.params, num_hiddens).detach().numpy()\n",
    "\n",
    "tmp_gamma = net.params[12].detach().numpy()\n",
    "gamma = np.zeros((num_train, num_sensors, num_hiddens))\n",
    "for i in range(num_train):\n",
    "    gamma[i] = tmp_gamma[i].T\n",
    "\n",
    "lam, Th = 0.1, 1.7 # 大于Th的时间点被认为是异常点\n",
    "valid_obv = []\n",
    "    \n",
    "for i in range(num_train):\n",
    "    unit_i = selected_unit[i] \n",
    "    L = df_train[df_train['Unit'] == unit_i+1].iloc[:,2:].values\n",
    "    tmp_n, q = lengths[i], 2\n",
    "    tmp_Psi = Psi[:tmp_n]\n",
    "\n",
    "    # 初始化\n",
    "    H = tmp_Psi @ inv(tmp_Psi.T @ tmp_Psi + 1e-6*np.diag(np.ones(tmp_Psi.shape[1]))) @ tmp_Psi.T\n",
    "    X = np.eye(H.shape[0]) - H\n",
    "\n",
    "\n",
    "    Y = X @ L\n",
    "    gamma = inv(X.T @ X + lam*np.eye(X.shape[0])) @ X.T @ Y\n",
    "    R = np.zeros(gamma.shape[0])\n",
    "\n",
    "    for j in range(gamma.shape[0]):\n",
    "        tmp_gamma = gamma[j].reshape(1,-1)\n",
    "        R[j] = tmp_gamma @ tmp_gamma.T\n",
    "\n",
    "    # update\n",
    "    valid_obv.append(np.where(R<Th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b45a4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obv = 0\n",
    "selected_obv = 0\n",
    "for i in range(num_train):\n",
    "    num_obv += lengths[i]\n",
    "    selected_obv += len(valid_obv[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac235bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023086574654956084"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_obv - selected_obv) / num_obv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d685141",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RNNModelScratch(num_inputs, num_hiddens, num_outputs, num_train, get_lstm_params, init_lstm_state, lstm)\n",
    "net.params = torch.load('LSTM-SVGD-Pre(20)-1-14.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0653c663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=1000, solver='sag')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [torch.tensor([i/500.0]) for i in range(500)]\n",
    "\n",
    "Psi = get_H(t, net.params, num_hiddens).detach().numpy()\n",
    "\n",
    "tmp_gamma = net.params[12].detach().numpy()\n",
    "gamma = np.zeros((num_train, num_sensors, num_hiddens))\n",
    "for i in range(num_train):\n",
    "    gamma[i] = tmp_gamma[i].T\n",
    "    \n",
    "# 计算传感器噪声方差\n",
    "sigma2 = np.zeros(num_sensors)\n",
    "\n",
    "for i in range(num_sensors):\n",
    "    tmp_sigma2 = 0\n",
    "    tmp_m = 0\n",
    "    for j in range(num_train):\n",
    "        gamma_j = gamma[j,i]\n",
    "        sensor_data = train_data[j][:,i].detach().numpy()\n",
    "        tmp_n = lengths[j]\n",
    "        \n",
    "        tmp_Psi = Psi[:tmp_n]\n",
    "        sensor_path = tmp_Psi @ gamma_j\n",
    "        \n",
    "        tmp_sigma2 += np.power(sensor_path - sensor_data, 2).sum()\n",
    "        tmp_m += (tmp_n - 6)\n",
    "        \n",
    "    sigma2[i] = tmp_sigma2/tmp_m\n",
    "    \n",
    "cov_list = []\n",
    "for i in range(num_sensors):\n",
    "    data_i = gamma[:,i]\n",
    "    cov_i = np.cov(data_i.T)\n",
    "    cov_list.append(cov_i)\n",
    "    \n",
    "cov = block_diag(cov_list[0],cov_list[1],cov_list[2],cov_list[3],cov_list[4],cov_list[5])\n",
    "# cov = np.cov(gamma.reshape(num_train,-1).T)\n",
    "mu = gamma.reshape(num_train,-1).mean(axis=0).reshape(-1,1)\n",
    "\n",
    "mu_i = np.zeros((num_train, 3*num_sensors,1)) \n",
    "cov_i = np.zeros((num_train,3*num_sensors,3*num_sensors))\n",
    "\n",
    "for i in range(num_train):\n",
    "    tmp_n = lengths[i]\n",
    "    obv_list = valid_obv[i]\n",
    "    tmp_psi = Psi[:tmp_n][obv_list]\n",
    "    \n",
    "    Psi_i = block_diag(tmp_psi,tmp_psi,tmp_psi,tmp_psi,tmp_psi,tmp_psi)\n",
    "    # 构建块对角矩阵\n",
    "    omega_i = np.diag(np.repeat(sigma2.reshape(-1,1),len(obv_list[0]),axis=1).flatten())\n",
    "\n",
    "    L_i = train_data[i][obv_list].detach().numpy().T.flatten().reshape(-1,1) # n_i*1\n",
    "    \n",
    "    # 计算后验分布\n",
    "    tmp_cov = inv(Psi_i.T @ inv(omega_i) @ Psi_i + inv(cov))\n",
    "    tmp_mu = tmp_cov @ (Psi_i.T @ inv(omega_i) @ L_i + inv(cov) @ mu)\n",
    "    \n",
    "    mu_i[i] = tmp_mu\n",
    "    cov_i[i] = tmp_cov\n",
    "    \n",
    "# 设置特征值-logistic regression\n",
    "N, delta, K = 80, 1, 25 # 超参数\n",
    "inputs = np.zeros((K*num_train,2*N,num_sensors))\n",
    "\n",
    "for i in range(num_train):\n",
    "    M = lengths[i]\n",
    "    gamma_samples = np.random.multivariate_normal(mu_i[i].flatten(), cov_i[i], size=K)  \n",
    "    \n",
    "    tt = torch.zeros(2*N, dtype=torch.long)\n",
    "    for j in range(2*N):\n",
    "        tt[j] = M + (j-N+1) * delta\n",
    "        \n",
    "    for k in range(K):\n",
    "        inputs[i*K+k] = (Psi @ gamma_samples[k].reshape(num_sensors,-1).T)[tt]\n",
    "        \n",
    "# 设置标签值\n",
    "labels = np.hstack((np.zeros(N), np.ones(N))).reshape(1,-1)\n",
    "# print(label.shape) (1,160)\n",
    "labels = np.repeat(labels, K*num_train, axis=0)\n",
    "\n",
    "X_train = inputs.reshape(-1,num_sensors)\n",
    "Y_train = labels.reshape(-1,1)\n",
    "X_train.shape, Y_train.shape\n",
    "\n",
    "model2 = LogisticRegression(penalty=\"l2\", C=0.01, solver=\"sag\", max_iter=1000) #创建模型\n",
    "model2.fit(X_train, Y_train.ravel()) #训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "905a9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam, Th = 0.1, 1.3\n",
    "    \n",
    "updated_data = []\n",
    "num_correct = 0\n",
    "num_obv = 0\n",
    "\n",
    "for i in range(num_test):\n",
    "    L = test_data[i]\n",
    "    tmp_n, q = test_lengths[i], 2\n",
    "    tmp_Psi = Psi[:tmp_n]\n",
    "    \n",
    "    num_obv += tmp_n\n",
    "    # B = (inv(tmp_Psi.T @ tmp_Psi) @ tmp_Psi.T @ L).T\n",
    "\n",
    "    # 初始化\n",
    "    H = tmp_Psi @ inv(tmp_Psi.T @ tmp_Psi + 1e-6*np.diag(np.ones(3))) @ tmp_Psi.T\n",
    "    X = np.eye(H.shape[0]) - H\n",
    "\n",
    "    for epoch in range(5):\n",
    "        Y = X @ L\n",
    "        gamma = inv(X.T @ X + lam*np.eye(X.shape[0])) @ X.T @ Y\n",
    "        R = np.zeros(gamma.shape[0])\n",
    "\n",
    "        for j in range(gamma.shape[0]):\n",
    "            tmp_gamma = gamma[j].reshape(1,-1)\n",
    "            R[j] = tmp_gamma @ tmp_gamma.T\n",
    "        \n",
    "        num_correct += len(np.where(R>Th)[0])\n",
    "        # update\n",
    "        L[np.where(R>Th)] = L[np.where(R>Th)] - gamma[np.where(R>Th)] # corrected\n",
    "     \n",
    "    updated_data.append(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddfdc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_j = np.zeros((num_test, num_hiddens*num_sensors,1)) \n",
    "cov_j = np.zeros((num_test,num_hiddens*num_sensors,num_hiddens*num_sensors))\n",
    "\n",
    "for i in range(num_test):\n",
    "    tmp_n = test_lengths[i]\n",
    "    tmp_psi = Psi[:tmp_n]\n",
    "    \n",
    "    Psi_i = block_diag(tmp_psi,tmp_psi,tmp_psi,tmp_psi,tmp_psi,tmp_psi)\n",
    "    # 构建块对角矩阵\n",
    "    omega_i = np.diag(np.repeat(sigma2.reshape(-1,1),tmp_n,axis=1).flatten())\n",
    "\n",
    "    L_i = updated_data[i].T.flatten().reshape(-1,1) # n_i*1\n",
    "    \n",
    "    # 计算后验分布\n",
    "    tmp_cov = inv(Psi_i.T @ inv(omega_i) @ Psi_i + inv(cov))\n",
    "    tmp_mu = tmp_cov @ (Psi_i.T @ inv(omega_i) @ L_i + inv(cov) @ mu)\n",
    "    \n",
    "    mu_j[i] = tmp_mu\n",
    "    cov_j[i] = tmp_cov\n",
    "\n",
    "results1 = np.zeros(50)\n",
    "results2 = np.zeros(50)\n",
    "results3 = np.zeros(50)\n",
    "\n",
    "for l in range(50):\n",
    "    # 设置特征值\n",
    "    K = 100 # 超参数\n",
    "    X_test = np.zeros((num_test, K, Psi.shape[0], num_sensors))\n",
    "    for i in range(num_test):\n",
    "        gamma_samples = np.random.multivariate_normal(mu_j[i].flatten(), cov_j[i], size=K)    \n",
    "        for k in range(K):\n",
    "            X_test[i,k] = Psi @ gamma_samples[k].reshape(num_sensors,-1).T\n",
    "            \n",
    "    pred_RUL = np.zeros(num_test)\n",
    "\n",
    "    for i in range(num_test):\n",
    "        \n",
    "        p = np.zeros((K, Psi.shape[0]))\n",
    "        for k in range(K):\n",
    "            x_i = X_test[i,k]\n",
    "            p[k] = model2.predict_proba(x_i)[:,1]\n",
    "        pp = p.mean(axis=0)\n",
    "        tmp_n = test_lengths[i]\n",
    "        p_T = (pp - pp[tmp_n])/(1 - pp[tmp_n])\n",
    "        pred_RUL[i] = np.where(p_T > 0.5)[0][0] - tmp_n\n",
    "        \n",
    "    error = np.abs(test_RUL - pred_RUL)/(test_RUL + test_lengths)\n",
    "    results1[l] = error.mean()\n",
    "    results2[l] = RMSE(test_RUL, pred_RUL)\n",
    "    results3[l] = score(test_RUL, pred_RUL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a120627b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06240275540629524, 0.0005517108058724928)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1.mean(), results1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14d70174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.009654996228054, 0.23748039807395274)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2.mean(), results2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65809358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8585.512897173014, 799.3899477918269)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3.mean(), results3.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
